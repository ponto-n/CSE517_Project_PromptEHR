{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrial.tasks.trial_simulation.sequence import PromptEHR\n",
    "from pytrial.data.demo_data import load_mimic_ehr_sequence\n",
    "from pytrial.tasks.trial_simulation.data import SequencePatient\n",
    "\n",
    "full_model_path = './model_50_epochs_30k_samples'\n",
    "partial_model_path = './model_20_epochs_15k_samples/'\n",
    "\n",
    "\n",
    "def load_model(path) -> PromptEHR:\n",
    "    model = PromptEHR()\n",
    "    model.from_pretrained(path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_seq_pat(data) -> SequencePatient:\n",
    "    return SequencePatient(\n",
    "        data={\n",
    "            'v': data['visit'],\n",
    "            'y': data['y'],\n",
    "            'x': data['feature'],\n",
    "        },\n",
    "        metadata={\n",
    "            'visit': {'mode': 'dense'},\n",
    "            'label': {'mode': 'tensor'},\n",
    "            'voc': data['voc'],\n",
    "            'max_visit': 20,\n",
    "            'n_num_feature': data['n_num_feature'],\n",
    "            'cat_cardinalities': data['cat_cardinalities'],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def load_seq_pat(path):\n",
    "    raw_data = load_mimic_ehr_sequence(input_dir=path)\n",
    "    return create_seq_pat(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrial.data.demo_data import load_synthetic_ehr_sequence\n",
    "raw_synth_data = load_synthetic_ehr_sequence()\n",
    "synth_data = create_seq_pat(raw_synth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained PromptEHR model from ./model_50_epochs_30k_samples\n",
      "Load the pre-trained model from: ./model_50_epochs_30k_samples\n",
      "evaluation for code diag.\n",
      "evaluation for tpl perplexity.\n",
      "code: diag, ppl_type: tpl, value: 2612.161376953125\n",
      "evaluation for code diag.\n",
      "evaluation for spl perplexity.\n",
      "code: diag, ppl_type: spl, value: 3272.134521484375\n",
      "evaluation for code prod.\n",
      "evaluation for tpl perplexity.\n",
      "code: prod, ppl_type: tpl, value: 1671.0849609375\n",
      "evaluation for code prod.\n",
      "evaluation for spl perplexity.\n",
      "code: prod, ppl_type: spl, value: 2932.37158203125\n",
      "evaluation for code med.\n",
      "evaluation for tpl perplexity.\n",
      "code: med, ppl_type: tpl, value: 358.09295654296875\n",
      "evaluation for code med.\n",
      "evaluation for spl perplexity.\n",
      "code: med, ppl_type: spl, value: 302.63525390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained PromptEHR model from ./model_20_epochs_15k_samples/\n",
      "Load the pre-trained model from: ./model_20_epochs_15k_samples/\n",
      "evaluation for code diag.\n",
      "evaluation for tpl perplexity.\n",
      "code: diag, ppl_type: tpl, value: 2881.69677734375\n",
      "evaluation for code diag.\n",
      "evaluation for spl perplexity.\n",
      "code: diag, ppl_type: spl, value: 4073.4453125\n",
      "evaluation for code prod.\n",
      "evaluation for tpl perplexity.\n",
      "code: prod, ppl_type: tpl, value: 1916.8770751953125\n",
      "evaluation for code prod.\n",
      "evaluation for spl perplexity.\n",
      "code: prod, ppl_type: spl, value: 2720.56689453125\n",
      "evaluation for code med.\n",
      "evaluation for tpl perplexity.\n",
      "code: med, ppl_type: tpl, value: 178.76751708984375\n",
      "evaluation for code med.\n",
      "evaluation for spl perplexity.\n",
      "code: med, ppl_type: spl, value: 212.9291534423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained PromptEHR model from ./simulation/pretrained_promptEHR\n",
      "Load the pre-trained model from: ./simulation/pretrained_promptEHR\n",
      "evaluation for code diag.\n",
      "evaluation for tpl perplexity.\n",
      "code: diag, ppl_type: tpl, value: 323.42999267578125\n",
      "evaluation for code diag.\n",
      "evaluation for spl perplexity.\n",
      "code: diag, ppl_type: spl, value: 501.9122314453125\n",
      "evaluation for code prod.\n",
      "evaluation for tpl perplexity.\n",
      "code: prod, ppl_type: tpl, value: 229.15621948242188\n",
      "evaluation for code prod.\n",
      "evaluation for spl perplexity.\n",
      "code: prod, ppl_type: spl, value: 165.3402557373047\n",
      "evaluation for code med.\n",
      "evaluation for tpl perplexity.\n",
      "code: med, ppl_type: tpl, value: 89.43730163574219\n",
      "evaluation for code med.\n",
      "evaluation for spl perplexity.\n",
      "code: med, ppl_type: spl, value: 64.30888366699219\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the different models on the synthetic data\n",
    "pretrained_model_path = None\n",
    "for path in [full_model_path, partial_model_path, pretrained_model_path]:\n",
    "    if path is not None:\n",
    "        model = load_model(path)\n",
    "    else:\n",
    "        path = 'pretrained_model'\n",
    "        model = PromptEHR()\n",
    "        model.from_pretrained()\n",
    "    model.evaluate(synth_data)\n",
    "    del model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained PromptEHR model from ./model_50_epochs_30k_samples\n",
      "Load the pre-trained model from: ./model_50_epochs_30k_samples\n",
      "522 reach model max length 512, do cut.\n",
      "512 reach model max length 512, do cut.\n",
      "523 reach model max length 512, do cut.\n",
      "529 reach model max length 512, do cut.\n",
      "516 reach model max length 512, do cut.\n",
      "523 reach model max length 512, do cut.\n",
      "529 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "522 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "514 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "528 reach model max length 512, do cut.\n",
      "{'lr': 0.0001, 'weight_decay': 0.0001}\n",
      "***** Running training *****\n",
      "  Num examples = 816\n",
      "  Num Epochs = 10\n",
      "  Total optimization steps = 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 135.39it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 133.60it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 136.81it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 141.85it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 141.27it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 144.41it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 135.38it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 81.74it/s]\n",
      "Training Epoch:  80%|████████  | 8/10 [00:00<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 100 #########\n",
      "0 0.5647 \n",
      "\n",
      "\n",
      "######### Eval 100 #########\n",
      "auc: 0.6169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 136.81it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 139.75it/s]\n",
      "Training Epoch: 100%|██████████| 10/10 [00:01<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best ckpt from `./checkpoints/best`.\n",
      "Training completes.\n",
      "0.6169154228855721\n",
      "{'lr': 0.0005, 'weight_decay': 0}\n",
      "***** Running training *****\n",
      "  Num examples = 700\n",
      "  Num Epochs = 50\n",
      "  Total optimization steps = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 48.62it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.03it/s]7it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.81it/s]5it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.80it/s]4it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]7it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 59.39it/s]3it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.56it/s]5it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.28it/s]5it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.03it/s]0it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.41it/s]7it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.54it/s]83it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]93it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.23it/s]93it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.53it/s]96it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.68it/s]95it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.62it/s]12it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 30.30it/s]96it/s]\n",
      "Training Epoch:  34%|███▍      | 17/50 [00:01<00:04,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 100 #########\n",
      "0 0.5160 \n",
      "\n",
      "\n",
      "######### Eval 100 #########\n",
      "auc: 0.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.75it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 59.39it/s]75it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.59it/s]27it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]56it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.53it/s]85it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.03it/s]88it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.56it/s]94it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.25it/s]91it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 51.71it/s]02it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.03it/s]85it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.13it/s]90it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.06it/s]05it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.24it/s]11it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.53it/s]09it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]04it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.84it/s]01it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 29.12it/s]82it/s]\n",
      "Training Epoch:  68%|██████▊   | 34/50 [00:03<00:02,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 200 #########\n",
      "0 0.2047 \n",
      "\n",
      "\n",
      "######### Eval 200 #########\n",
      "auc: 0.6478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.86it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.06it/s]62it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.22it/s]05it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.56it/s]32it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 59.39it/s]47it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.53it/s]83it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]88it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 59.39it/s]90it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.59it/s]15it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.56it/s]21it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.06it/s]10it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.03it/s]12it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.75it/s]08it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]12it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 51.71it/s]04it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 26.43it/s]86it/s]\n",
      "Training Epoch: 100%|██████████| 50/50 [00:05<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 300 #########\n",
      "0 0.0172 \n",
      "\n",
      "\n",
      "######### Eval 300 #########\n",
      "auc: 0.6531\n",
      "Load best ckpt from `./checkpoints/best`.\n",
      "Training completes.\n",
      "{'lr': 0.0005, 'weight_decay': 0}\n",
      "***** Running training *****\n",
      "  Num examples = 14\n",
      "  Num Epochs = 50\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 49.99it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 29.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 31.24it/s]0it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 33.33it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 49.99it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]4it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 19.75it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 66.65it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.61it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]5it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.83it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.83it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.81it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.62it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.94it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.96it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.95it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.64it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.62it/s]2it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.62it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.99it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.95it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.94it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 249.91it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.64it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.64it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.96it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.64it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.96it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.61it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]5it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.96it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.62it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 199.96it/s]\n",
      "Training Epoch: 100%|██████████| 50/50 [00:00<00:00, 78.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completes.\n",
      "{'real-data-model-auc': 0.6531165311653117, 'syn-data-model-auc': 0.5301866907557965}\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data for each model and evalutate on privacy\n",
    "from pytrial.tasks.trial_simulation.sequence.evaluation import RNNPrivacyDetection, RNNUtilityDetection\n",
    "\n",
    "# Full model\n",
    "full_model = load_model(full_model_path)\n",
    "synthetic_seqdata = full_model.predict(synth_data, n=20, n_per_sample=1, verbose=False)\n",
    "del full_model\n",
    "# Evaluate privacy\n",
    "print(RNNPrivacyDetection.compute(synth_data, synthetic_seqdata, device='cuda:0'))\n",
    "# Evaluate utility\n",
    "print(RNNUtilityDetection.compute(synth_data, synthetic_seqdata, device='cuda:0'))\n",
    "del synthetic_seqdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained PromptEHR model from ./model_20_epochs_15k_samples/\n",
      "Load the pre-trained model from: ./model_20_epochs_15k_samples/\n",
      "522 reach model max length 512, do cut.\n",
      "521 reach model max length 512, do cut.\n",
      "531 reach model max length 512, do cut.\n",
      "514 reach model max length 512, do cut.\n",
      "514 reach model max length 512, do cut.\n",
      "514 reach model max length 512, do cut.\n",
      "512 reach model max length 512, do cut.\n",
      "532 reach model max length 512, do cut.\n",
      "512 reach model max length 512, do cut.\n",
      "520 reach model max length 512, do cut.\n",
      "516 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "523 reach model max length 512, do cut.\n",
      "513 reach model max length 512, do cut.\n",
      "515 reach model max length 512, do cut.\n",
      "{'lr': 0.0001, 'weight_decay': 0.0001}\n",
      "***** Running training *****\n",
      "  Num examples = 816\n",
      "  Num Epochs = 10\n",
      "  Total optimization steps = 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 141.27it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 144.41it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 146.03it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 142.82it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 133.99it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 138.27it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 83.31it/s]\n",
      "Training Epoch:  80%|████████  | 8/10 [00:00<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 100 #########\n",
      "0 0.6480 \n",
      "\n",
      "\n",
      "######### Eval 100 #########\n",
      "auc: 0.4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 131.06it/s]\n",
      "Training Epoch: 100%|██████████| 10/10 [00:01<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best ckpt from `./checkpoints/best`.\n",
      "Training completes.\n",
      "0.43875\n",
      "{'lr': 0.0005, 'weight_decay': 0}\n",
      "***** Running training *****\n",
      "  Num examples = 700\n",
      "  Num Epochs = 50\n",
      "  Total optimization steps = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.08it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.24it/s]7it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]8it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.16it/s]0it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 48.77it/s]9it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]1it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 51.71it/s]5it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.34it/s]1it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 53.08it/s]7it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.61it/s]1it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 48.77it/s]78it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.53it/s]50it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 49.99it/s]65it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.68it/s]53it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.16it/s]78it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.13it/s]75it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 30.30it/s]95it/s]\n",
      "Training Epoch:  34%|███▍      | 17/50 [00:02<00:04,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 100 #########\n",
      "0 0.4961 \n",
      "\n",
      "\n",
      "######### Eval 100 #########\n",
      "auc: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.13it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.41it/s]76it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]92it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 49.58it/s]20it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.16it/s]18it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 48.38it/s]30it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 49.99it/s]19it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.16it/s]21it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 49.99it/s]33it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.16it/s]31it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 55.03it/s]38it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 51.27it/s]58it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.41it/s]55it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 52.62it/s]46it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 46.50it/s]53it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 44.11it/s]24it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 22.72it/s]93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 200 #########\n",
      "0 0.1859 \n",
      "\n",
      "\n",
      "######### Eval 200 #########\n",
      "auc: 0.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 44.43it/s]94it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 43.79it/s]29it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 45.44it/s]52it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 47.61it/s]79it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.84it/s]05it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 51.27it/s]41it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 47.39it/s]70it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 45.79it/s]72it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 48.53it/s]66it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.41it/s]75it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 47.99it/s]91it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 50.58it/s]92it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 47.23it/s]03it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 49.17it/s]96it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 51.71it/s]99it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 26.54it/s]13it/s]\n",
      "Training Epoch: 100%|██████████| 50/50 [00:06<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 300 #########\n",
      "0 0.0149 \n",
      "\n",
      "\n",
      "######### Eval 300 #########\n",
      "auc: 0.6364\n",
      "Load best ckpt from `./checkpoints/best`.\n",
      "Training completes.\n",
      "{'lr': 0.0005, 'weight_decay': 0}\n",
      "***** Running training *****\n",
      "  Num examples = 14\n",
      "  Num Epochs = 50\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 58.81it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]2it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 35.71it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 47.61it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 38.45it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 37.03it/s]67it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 52.62it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]54it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 47.61it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]67it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]9it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.83it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]16it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 125.08it/s]\n",
      "Training Epoch: 100%|██████████| 50/50 [00:00<00:00, 71.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completes.\n",
      "{'real-data-model-auc': 0.6567497966928707, 'syn-data-model-auc': 0.40329357549471406}\n"
     ]
    }
   ],
   "source": [
    "# Partial model\n",
    "partial_model = load_model(partial_model_path)\n",
    "synthetic_seqdata = partial_model.predict(synth_data, n=20, n_per_sample=1, verbose=False)\n",
    "del partial_model\n",
    "# Evaluate privacy\n",
    "print(RNNPrivacyDetection.compute(synth_data, synthetic_seqdata, device='cuda:0'))\n",
    "# Evaluate utility\n",
    "print(RNNUtilityDetection.compute(synth_data, synthetic_seqdata, device='cuda:0'))\n",
    "del synthetic_seqdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained PromptEHR model from ./simulation/pretrained_promptEHR\n",
      "Load the pre-trained model from: ./simulation/pretrained_promptEHR\n",
      "514 reach model max length 512, do cut.\n",
      "516 reach model max length 512, do cut.\n",
      "514 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "515 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "517 reach model max length 512, do cut.\n",
      "514 reach model max length 512, do cut.\n",
      "512 reach model max length 512, do cut.\n",
      "518 reach model max length 512, do cut.\n",
      "520 reach model max length 512, do cut.\n",
      "519 reach model max length 512, do cut.\n",
      "513 reach model max length 512, do cut.\n",
      "516 reach model max length 512, do cut.\n",
      "{'lr': 0.0001, 'weight_decay': 0.0001}\n",
      "***** Running training *****\n",
      "  Num examples = 816\n",
      "  Num Epochs = 10\n",
      "  Total optimization steps = 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 151.13it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 154.73it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 146.03it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 152.91it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 154.72it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 152.91it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 156.59it/s]/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 81.74it/s]\n",
      "Training Epoch:  80%|████████  | 8/10 [00:00<00:00,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 100 #########\n",
      "0 0.6069 \n",
      "\n",
      "\n",
      "######### Eval 100 #########\n",
      "auc: 0.5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 154.73it/s]\n",
      "Iteration: 100%|██████████| 13/13 [00:00<00:00, 144.41it/s]\n",
      "Training Epoch: 100%|██████████| 10/10 [00:00<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best ckpt from `./checkpoints/best`.\n",
      "Training completes.\n",
      "0.5336700336700337\n",
      "{'lr': 0.0005, 'weight_decay': 0}\n",
      "***** Running training *****\n",
      "  Num examples = 700\n",
      "  Num Epochs = 50\n",
      "  Total optimization steps = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 60.23it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]4it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 54.04it/s]1it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 61.21it/s]5it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 60.59it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.13it/s]6it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 60.59it/s]9it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.68it/s]8it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.14it/s]3it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.14it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.13it/s]95it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.14it/s]82it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 62.75it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 65.20it/s]02it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 61.84it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 62.48it/s]16it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 28.16it/s]\n",
      "Training Epoch:  34%|███▍      | 17/50 [00:01<00:03,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 100 #########\n",
      "0 0.5025 \n",
      "\n",
      "\n",
      "######### Eval 100 #########\n",
      "auc: 0.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.14it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.68it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 59.39it/s]89it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.80it/s]05it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 56.59it/s]19it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 66.93it/s]20it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 64.50it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 59.39it/s]75it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.68it/s]74it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]69it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 62.49it/s]67it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 57.34it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 61.21it/s]73it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 60.59it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 60.59it/s]83it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 68.17it/s]87it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 31.82it/s]\n",
      "Training Epoch:  68%|██████▊   | 34/50 [00:03<00:01,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 200 #########\n",
      "0 0.1957 \n",
      "\n",
      "\n",
      "######### Eval 200 #########\n",
      "auc: 0.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 65.49it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]11it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 61.21it/s]21it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.81it/s]37it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 61.21it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.14it/s]70it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 65.92it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 65.20it/s]99it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 63.14it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.81it/s]17it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 64.50it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 66.64it/s]13it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 58.24it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 66.21it/s]15it/s]\n",
      "Iteration: 100%|██████████| 6/6 [00:00<00:00, 29.26it/s]\n",
      "Training Epoch: 100%|██████████| 50/50 [00:05<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Train Loss 300 #########\n",
      "0 0.0170 \n",
      "\n",
      "\n",
      "######### Eval 300 #########\n",
      "auc: 0.6070\n",
      "Load best ckpt from `./checkpoints/best`.\n",
      "Training completes.\n",
      "{'lr': 0.0005, 'weight_decay': 0}\n",
      "***** Running training *****\n",
      "  Num examples = 14\n",
      "  Num Epochs = 50\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 66.65it/s]5it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 66.65it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 66.65it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 58.81it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 66.65it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]69it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]84it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 66.65it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]37it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]5it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.97it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 142.82it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 83.31it/s]\n",
      "Training Epoch: 100%|██████████| 50/50 [00:00<00:00, 81.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completes.\n",
      "{'real-data-model-auc': 0.6138519924098672, 'syn-data-model-auc': 0.41257793439956625}\n"
     ]
    }
   ],
   "source": [
    "# Pretrained model\n",
    "pre_model = PromptEHR()\n",
    "pre_model.from_pretrained()\n",
    "synthetic_seqdata = pre_model.predict(synth_data, n=20, n_per_sample=1, verbose=False)\n",
    "del pre_model\n",
    "# Evaluate privacy\n",
    "print(RNNPrivacyDetection.compute(synth_data, synthetic_seqdata, device='cuda:0'))\n",
    "# Evaluate utility\n",
    "print(RNNUtilityDetection.compute(synth_data, synthetic_seqdata, device='cuda:0'))\n",
    "del synthetic_seqdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse517",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
